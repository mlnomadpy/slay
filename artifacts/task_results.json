{
  "config": {
    "embed_dim": 64,
    "num_heads": 4,
    "n_layers": 2,
    "ff_dim": 256,
    "batch_size": 32,
    "num_epochs": 50,
    "lr": 0.001,
    "eval_every": 10,
    "num_seeds": 1,
    "seed": 42,
    "slay_num_features": 32,
    "slay_num_quad": 2,
    "slay_poly_dim": 16,
    "slay_prf_dim": 8,
    "performer_kernel_size": 64,
    "rff_num_features": 64
  },
  "results": [
    {
      "task": "copy",
      "category": "basic",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "copy",
      "category": "basic",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "reverse",
      "category": "basic",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "sort",
      "category": "basic",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "retrieval",
      "category": "memory",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "selective_copy",
      "category": "memory",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "first_token",
      "category": "memory",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "counting",
      "category": "arithmetic",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "parity",
      "category": "arithmetic",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "long_copy",
      "category": "long_range",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "standard",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "linear",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "performer",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay-tensor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "SLAYTensorAttention.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay-laplace",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay-rm",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay-nystrom",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "_SLAYPolyBase.__init__() got an unexpected keyword argument 'num_features'. Did you mean 'num_prf_features'?"
    },
    {
      "task": "distant_match",
      "category": "long_range",
      "attention": "slay-anchor",
      "final_loss": NaN,
      "final_accuracy": NaN,
      "error": "Missing required argument `wrt`. As of Flax 0.11.0 the `wrt` argument is required, if you want to keep the previous use nnx.ModelAndOptimizer instead of nnx.Optimizer."
    }
  ]
}