\begin{table}[t]
\centering
\small
\caption{Attention latency (ms (fwd+bwd)) at various sequence lengths.}
\label{tab:latency-scaling_backward}
\begin{tabular}{lrrrr}
\toprule
Method & 256 & 512 & 1K & 2K \\
\midrule
standard & 5.92 & 18.77 & 48.02 & 183.22 \\
rotary & -- & -- & -- & -- \\
linear & 3.32 & 6.16 & 9.59 & 18.29 \\
performer & 6.12 & 10.40 & 15.67 & 26.75 \\
cosformer & 4.32 & 7.24 & 14.89 & 27.76 \\
rff & 8.59 & 12.83 & 24.09 & 42.72 \\
yat & 6.48 & 19.82 & 59.22 & 231.10 \\
yat-spherical & 6.22 & 17.29 & 47.83 & 195.76 \\
slay & 6.73 & 11.11 & 19.55 & 33.06 \\
slay-tensor & -- & -- & -- & -- \\
slay-laplace & 6.47 & 12.80 & 17.23 & 31.70 \\
slay-rm & 8.96 & 13.38 & 28.39 & 53.32 \\
slay-nystrom & 7.68 & 13.35 & 27.51 & 49.42 \\
slay-anchor & 8.85 & 14.41 & 33.76 & 86.63 \\
\bottomrule
\end{tabular}
\end{table}