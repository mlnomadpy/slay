\begin{table}[t]
\centering
\small
\caption{Attention latency (ms (fwd+bwd)) at various sequence lengths.}
\label{tab:latency-scaling_backward}
\begin{tabular}{lrrrr}
\toprule
Method & 256 & 512 & 1K & 2K \\
\midrule
standard & 7.85 & 23.89 & 66.24 & 220.68 \\
rotary & -- & -- & -- & -- \\
linear & 5.05 & 8.42 & 14.20 & 26.25 \\
performer & 6.95 & 12.14 & 24.16 & 34.55 \\
cosformer & 5.64 & 9.44 & 21.26 & 31.53 \\
rff & 9.31 & 16.14 & 31.45 & 62.50 \\
yat & 9.70 & 23.85 & 93.44 & 272.44 \\
yat-spherical & 9.10 & 24.67 & 73.79 & 279.51 \\
slay & 6.54 & 14.59 & 26.10 & 49.31 \\
slay-tensor & -- & -- & -- & -- \\
slay-laplace & 9.54 & 12.26 & 22.18 & 48.27 \\
slay-rm & 10.71 & 17.04 & 37.86 & 69.85 \\
slay-nystrom & 9.70 & 16.43 & 33.12 & 61.40 \\
slay-anchor & 10.18 & 16.90 & 39.51 & 62.18 \\
\bottomrule
\end{tabular}
\end{table}