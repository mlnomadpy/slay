\begin{table}[t]
\centering
\small
\caption{Attention latency (ms (fwd+bwd)) at various sequence lengths.}
\label{tab:latency-scaling_backward}
\begin{tabular}{lrrrr}
\toprule
Method & 256 & 512 & 1K & 2K \\
\midrule
standard & 6.36 & 18.75 & 42.18 & 157.74 \\
rotary & -- & -- & -- & -- \\
linear & 3.36 & 6.06 & 10.56 & 20.85 \\
performer & 6.26 & 9.65 & 17.72 & 38.38 \\
cosformer & 5.39 & 7.84 & 14.31 & 24.34 \\
rff & 8.29 & 14.62 & 23.45 & 45.11 \\
yat & 6.56 & 19.05 & 49.29 & 211.00 \\
yat-spherical & 6.59 & 19.46 & 45.48 & 178.72 \\
slay & 6.93 & 13.59 & 23.76 & 45.09 \\
slay-tensor & -- & -- & -- & -- \\
slay-laplace & 9.04 & 16.44 & 23.64 & 52.11 \\
slay-rm & 12.76 & 20.36 & 45.67 & 85.11 \\
slay-nystrom & 11.55 & 23.85 & 41.87 & 63.36 \\
slay-anchor & 11.30 & 18.41 & 37.69 & 67.95 \\
\bottomrule
\end{tabular}
\end{table}